{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from common import get_train, get_test, get_parking, feat_eng, premodel_formating, mean_target_enc, get_XY\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import KFold\n",
    "from common import load_clean_train, load_clean_test, extract_dates, add_midpoint_loc_id, tt_join_city_stats2clean, load_clean_parking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_score(m, X, y):\n",
    "    preds = m.predict(X)\n",
    "    p = precision_score(y, preds)\n",
    "    r = recall_score(y, preds)\n",
    "    return (1.25*p*r/(0.25*p+r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def writeToFile(preds, filename):\n",
    "    result = \"id,any_spot\"\n",
    "    for i in range(0, len(preds)):\n",
    "        result = result + \"\\n\" + str(i + 1) + \",\" + str(preds[i]) \n",
    "    # return result\n",
    "    file = open(filename,\"w\")  \n",
    "    file.write(result)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_k(X, y, k, model):\n",
    "    kf = KFold(n_splits = k)\n",
    "    kf.get_n_splits(X)\n",
    "    # f0.5 score\n",
    "    f_score = 0\n",
    "    # precision\n",
    "    p_score = 0\n",
    "    # recall\n",
    "    r_score = 0\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.ix[train_index], X.ix[val_index]    \n",
    "        y_train, y_val = y.ix[train_index], y.ix[val_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_val)\n",
    "        f_score += fbeta_score(y_val, preds, beta=0.5)\n",
    "        p_score += precision_score(y_val, preds)\n",
    "        r_score += recall_score(y_val, preds)\n",
    "    return [f_score/(k*1.0), p_score/(k*1.0), r_score/(k*1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 18) (726, 16)\n",
      "(1100, 26) (726, 24)\n",
      "(1100, 27) (726, 25)\n",
      "(1100, 31) (726, 29)\n"
     ]
    }
   ],
   "source": [
    "import warnings; warnings.simplefilter('ignore')\n",
    "train_df = load_clean_train()\n",
    "test_df = load_clean_test()\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "train_df = extract_dates(train_df)\n",
    "test_df = extract_dates(test_df)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "train_df = add_midpoint_loc_id(train_df)\n",
    "test_df = add_midpoint_loc_id(test_df)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "train_df = tt_join_city_stats2clean(train_df)\n",
    "test_df = tt_join_city_stats2clean(test_df)\n",
    "print(train_df.shape, test_df.shape)\n",
    "\n",
    "#train_df = premodel_formating(train_df, split=False)\n",
    "#test_df = premodel_formating(test_df, split=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop\n",
      "area\n",
      "med_age\n"
     ]
    }
   ],
   "source": [
    "# drop nulls\n",
    "for col in train_df:\n",
    "    if train_df[col].isna().sum() != 0:\n",
    "        print(col)\n",
    "        train_df = train_df.drop(col, axis = 1)\n",
    "        test_df = test_df.drop(col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Date\n",
    "train_df = train_df.drop('Date', axis = 1)\n",
    "test_df = test_df.drop('Date', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Street to unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_list = list(set().union(train_df[\"Street\"], train_df[\"From\"], train_df[\"To\"]))\n",
    "street_map = {}\n",
    "for i in range(0, len(train_list)):\n",
    "    street_map[train_list[i]] = i + 1\n",
    "# Update train\n",
    "train_df = train_df.replace({\"Street\": street_map})\n",
    "train_df = train_df.replace({\"From\": street_map})\n",
    "train_df = train_df.replace({\"To\": street_map})\n",
    "# Update test\n",
    "test_df = test_df.replace({\"Street\": street_map})\n",
    "test_df = test_df.replace({\"From\": street_map})\n",
    "test_df = test_df.replace({\"To\": street_map})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = list(set().union(train_df[\"Clean_Street\"], train_df[\"Clean_From\"], train_df[\"Clean_To\"]))\n",
    "street_map = {}\n",
    "for i in range(0, len(train_list)):\n",
    "    street_map[train_list[i]] = i + 1\n",
    "# Update train\n",
    "train_df = train_df.replace({\"Clean_Street\": street_map})\n",
    "train_df = train_df.replace({\"Clean_From\": street_map})\n",
    "train_df = train_df.replace({\"Clean_To\": street_map})\n",
    "# Update test\n",
    "test_df = test_df.replace({\"Clean_Street\": street_map})\n",
    "test_df = test_df.replace({\"Clean_From\": street_map})\n",
    "test_df = test_df.replace({\"Clean_To\": street_map})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all non-numeric columns\n",
    "for col in train_df:\n",
    "    if train_df[col].dtype == \"object\":\n",
    "        train_df = train_df.drop(col, axis = 1)\n",
    "        test_df = test_df.drop(col, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_df.drop([\"Real.Spots\", \"any_spot\"], axis=1)\n",
    "y = train_df[\"any_spot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.220180305132 [1, 1, 0.10000000000000001]\n",
      "0.236185383244 [2, 1, 0.10000000000000001]\n",
      "0.36344519762 [3, 1, 0.10000000000000001]\n",
      "0.496516893069 [4, 1, 0.10000000000000001]\n",
      "0.498649733658 [8, 1, 0.10000000000000001]\n",
      "0.510563498035 [9, 1, 0.10000000000000001]\n",
      "0.536532433084 [4, 2, 0.10000000000000001]\n",
      "0.571056464321 [4, 2, 0.20000000000000001]\n",
      "0.576715402773 [4, 2, 0.30000000000000004]\n",
      "10\n",
      "0.578186546539 [5, 15, 0.30000000000000004]\n",
      "20\n",
      "30\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "depths = np.arange(0, 10) + 1\n",
    "rates = np.arange(0.1, 0.5, 0.1)\n",
    "best_f_score = 0\n",
    "for i in range(0, 50):\n",
    "    if i % 10 == 0: print(i)\n",
    "    for depth in depths:\n",
    "        for rate in rates:\n",
    "            model = xgb.XGBClassifier (max_depth=depth, n_estimators=i, n_jobs=-1,\\\n",
    "                                        learning_rate=rate)\n",
    "            result = cv_k(X, y, 2, model)\n",
    "            if result[1] > best_f_score:\n",
    "                print(result[1], [depth, i, rate])\n",
    "                best_f_score = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38962197457995579, 0.51801884218466621, 0.25783097546982353]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# leader board score : 0.62682 (parameter tuning using 3-cross validation)\n",
    "model = xgb.XGBClassifier(max_depth=3, learning_rate=0.3, n_estimators=22, n_jobs=-1)\n",
    "# model.fit(X, y)\n",
    "cv_k(X, y, 3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0.5 is :  0.201465201465\n",
      "precision is :  0.239130434783\n",
      "recall is :  0.123595505618\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val = train_test_split(X, test_size=0.25)\n",
    "y_train, y_val = train_test_split(y, test_size=0.25)\n",
    "model = xgb.XGBClassifier(max_depth=3, learning_rate=0.3, n_estimators=22, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_val)\n",
    "print(\"f0.5 is : \", fbeta_score(y_val, preds, beta=0.5))\n",
    "print(\"precision is : \", precision_score(y_val, preds))\n",
    "print(\"recall is : \", recall_score(y_val, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(825, 22) (275, 22) (825,) (275,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.3, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=15,\n",
       "       n_jobs=-1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# leader board score : 0.61445 (parameter tuning using 2-cross validation)\n",
    "model = xgb.XGBClassifier(max_depth=5, learning_rate=0.3, n_estimators=15, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "# cv_k(X, y, 3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preds = model.predict(test_df)\n",
    "# writeToFile(preds, \"submissions/submission_xg_no_enc_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### RF without mean encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f0.5 is :  0.204778156997\n",
      "precision is :  0.235294117647\n",
      "recall is :  0.134831460674\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1, n_estimators=4,min_samples_leaf=11,max_features=0.3, max_depth = 7)\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_val)\n",
    "print(\"f0.5 is : \", fbeta_score(y_val, preds, beta=0.5))\n",
    "print(\"precision is : \", precision_score(y_val, preds))\n",
    "print(\"recall is : \", recall_score(y_val, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41664432918302885, 0.54867724867724865, 0.28856249621016006]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4, 11, 0.30000000000000004, 7,\n",
    "# leaderboard score 0.57071\n",
    "m = RandomForestClassifier(n_jobs=-1, n_estimators=4,min_samples_leaf=11,max_features=0.3, max_depth = 7)\n",
    "# m.fit(X, y)\n",
    "# cv_k(X, y, 3, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds3 = m.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "623"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds3 == preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writeToFile(preds3, \"submissions/submission_rf_no_enc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_ones.csv   mean_enc_sub.csv       submission_xg_no_enc.csv\r\n",
      "all_zeros.csv  submission_xg_enc.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
